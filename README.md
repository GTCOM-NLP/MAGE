# MAGE: Multimodal Alignment and Generation Enhancement via Bridging Visual and Semantic Spaces

### Official Implementation of the [IJCAI 2025](https://www.ijcai.org/) Main Track Paper

**Authors:**  
Shaojun E<sup>1,3,†</sup>, Yuchen Yang<sup>2,†</sup>, JiaHeng Wu<sup>2</sup>, Yan Zhang<sup>1</sup>, Tiejun Zhao<sup>2</sup>, Ziyan Chen<sup>1,\*</sup>

<sub><sup>†</sup> Equal contribution | <sup>\*</sup> Corresponding author</sub>

**Affiliations:**  
<sup>1</sup> Global Tone Communication Technology Co., Ltd., Beijing, China  
<sup>2</sup> Harbin Institute of Technology, Harbin, China  
<sup>3</sup> School of Computer Science and Technology, Beijing Jiaotong University, Beijing, China  

**Contact:**  
- eshaojun@gtcom.com.cn  
- chenziyan@gtcom.com.cn  
- zhangyan01@gtcom.com.cn
- 23S003057@stu.hit.edu.cn  
- 23S136126@stu.hit.edu.cn  
- tjzhao@hit.edu.cn  

> 📄 Accepted at **IJCAI 2025** | 🧠 Multimodal Learning | 👁️ Vision & Language

<div align="center">

[![Paper PDF](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/abs/2507.21741)
![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue?style=for-the-badge)
![Project Page](https://img.shields.io/badge/Project-Page-green?style=for-the-badge)
![Demo Page](https://img.shields.io/badge/Demo-Page-orange?style=for-the-badge)
</div>

## ✨ Highlights

- Bridging visual and semantic spaces via dual-path alignment and generation.
- Boosts both multimodal generation and cross-modal retrieval.
- State-of-the-art results on benchmark datasets: MS-COCO, Flickr30K, etc.
- Modular design for easy integration and extension.

## 📰 News

- **[2025.05.15]** 🎉 We will release our work quickly.

## 📄 Paper

**Title:** MAGE: Multimodal Alignment and Generation Enhancement via Bridging Visual and Semantic Spaces  
**Conference:** International Joint Conference on Artificial Intelligence (IJCAI), 2025  
**PDF:** [Link to Paper (arXiv)](https://arxiv.org/abs/2507.21741)
